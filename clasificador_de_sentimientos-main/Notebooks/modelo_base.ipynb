{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-Js0-mpTSL1",
        "outputId": "632cbb80-7268-4ad3-c081-86d0eb25f866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dropout, MaxPool1D, Flatten, Dense, ReLU, Input, BatchNormalization, Softmax\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.advanced_activations import Softmax\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT77427uTSL3"
      },
      "source": [
        "# Modelo base propuesto por Dias Issa et al."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2eD6AeuHTSL5"
      },
      "outputs": [],
      "source": [
        "def build_baseline():\n",
        "  model = Sequential()\n",
        "\n",
        "  # input layer\n",
        "  model.add(Input(shape=(193, 1)))\n",
        "  \n",
        "  # Primer Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=255, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "\n",
        "  # Segund Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  # Capa de Maxpooling\n",
        "  model.add(MaxPool1D(pool_size=8))\n",
        "\n",
        "  # 3 capas convolucionales intermedias\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa convolucional final\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa densa, tiene la misma cantidad de neuronas que de clases a predecir\n",
        "  model.add(Dense(units=8))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Softmax())  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = build_baseline()\n",
        "model.compile(optimizer = RMSprop(learning_rate=1e-5) , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "modelo_base.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
