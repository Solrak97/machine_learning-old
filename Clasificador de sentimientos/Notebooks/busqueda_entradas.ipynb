{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8YdYrT9HrDK"
      },
      "source": [
        "# Busqueda de entradas para el modelo base propuesto por Dias Issa et al.\n",
        "El modelo base cuenta con una entrada de 193 nodos, por lo que es necesario que cada entrada de datos tenga exactamente 193 variables, eso a partir de las ya conocidas caracteristicas \n",
        "\n",
        "* Chromagram\n",
        "* Contrast\n",
        "* Mel coeficent\n",
        "* Mel frequency\n",
        "* Tonnetz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB9TIer0KDXV"
      },
      "source": [
        "### Descarga de los datos desde Kaggle hasta el notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xj4nwWzWHrDV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle wavio pydub keras-metrics\n",
        "! rm -rf *\n",
        "! mkdir ~/.kaggle\n",
        "! curl https://raw.githubusercontent.com/Solrak97/clasificador_de_sentimientos/main/kaggle.json > kaggle.json\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download uwrfkaggler/ravdess-emotional-speech-audio\n",
        "! unzip ravdess-emotional-speech-audio.zip\n",
        "\n",
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "from pydub import AudioSegment\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA9jS5ZnY6tt"
      },
      "source": [
        "### Algoritmo de extracción de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRDBB79PY-Xx"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\") \n",
        "\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "      \n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=80).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "           \n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "           \n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate, n_mels=80).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "           \n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "           \n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "           \n",
        "    return result\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ7z173BZfv3"
      },
      "outputs": [],
      "source": [
        "# we allow only these emotions ( feel free to tune this on your need )\n",
        "AVAILABLE_EMOTIONS = {\n",
        "    \"neutral\",\n",
        "    \"calm\",\n",
        "    \"happy\",\n",
        "    \"sad\",\n",
        "    \"angry\",\n",
        "    \"fearful\",\n",
        "    \"disgust\",\n",
        "    \"surprised\"\n",
        "}\n",
        "\n",
        "'''\n",
        "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "Vocal channel (01 = speech, 02 = song).\n",
        "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "'''\n",
        "\n",
        "INT_2_MODALITY = {\n",
        "    '01' : 'full-AV',\n",
        "    '02' : 'video-only',\n",
        "    '03' : 'audio-only'\n",
        "}\n",
        "\n",
        "INT_2_VOCAL = {\n",
        "    '01' : 'speech',\n",
        "    '02' : 'song'\n",
        "}\n",
        "\n",
        "INT_2_EMOTION = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "INT_2_INTENSITY = {\n",
        "    '01' : 'normal', \n",
        "    '02' : 'strong'\n",
        "}\n",
        "\n",
        "INT_2_STATEMENT = {\n",
        "    '01' : '\"Kids are talking by the door\"',\n",
        "    '02' : '\"Dogs are sitting by the door\"'\n",
        "}\n",
        "\n",
        "INT_2_REPETITION = {\n",
        "    '01' : '1st repetition', \n",
        "    '02' : '2nd repetition'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu1dHnJfZQ3d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_data():\n",
        "\n",
        "    _modality = []\n",
        "    _vocal_channel = []\n",
        "    _emotions = []\n",
        "    _intensity = []\n",
        "    _statement = []\n",
        "    _repetition = []\n",
        "    _actor = []\n",
        "    _features = []\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for file in glob.glob(\"Actor_*/*.wav\"):\n",
        "            \n",
        "      file_name = os.path.basename(file)\n",
        "      \n",
        "      # El audio viene en estereo para algunas partes\n",
        "      # Así que se pasa a mono\n",
        "      sound = AudioSegment.from_wav(file)\n",
        "      sound = sound.set_channels(1)\n",
        "      sound.export(file, format=\"wav\")\n",
        "  \n",
        "      name_split = file_name.split(\"-\")\n",
        "      emotion = INT_2_EMOTION[name_split[2]]\n",
        "\n",
        "      # Limitación de emociones.\n",
        "      if emotion not in AVAILABLE_EMOTIONS:\n",
        "        continue\n",
        "      \n",
        "      _modality.append(INT_2_MODALITY[name_split[0]])\n",
        "      _vocal_channel.append(INT_2_VOCAL[name_split[1]])\n",
        "      _intensity.append(INT_2_INTENSITY[name_split[3]])\n",
        "      _statement.append(INT_2_STATEMENT[name_split[4]])\n",
        "      _repetition.append(INT_2_REPETITION[name_split[5]])\n",
        "      _actor.append(name_split[6])\n",
        "      _emotions.append(emotion)\n",
        "\n",
        "      # Extracción de los datos graciosos\n",
        "      features = extract_feature(file, mfcc=True, \n",
        "                                 chroma=True, mel=True, \n",
        "                                 contrast=True, tonnetz=True)\n",
        "      \n",
        "      _features.append(features)\n",
        "\n",
        "\n",
        "    data = {\n",
        "      'Modality' :  _modality,\n",
        "      'Vocal Channel' : _vocal_channel,\n",
        "      'Emotion' : _emotions,\n",
        "      'Intensity' : _intensity,\n",
        "      'Statement' : _statement,\n",
        "      'Repetition' : _repetition,\n",
        "      'Actor_ID' : _actor,\n",
        "      'Features' : _features\n",
        "    } \n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "EZtp5chmZy0m",
        "outputId": "b9cdc25a-22bc-4fb1-a17a-3fb8c962ad6a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7952ade14796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-685370909cd3>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actor_*/*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ],
      "source": [
        "data = load_data()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "busqueda_entradas.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
