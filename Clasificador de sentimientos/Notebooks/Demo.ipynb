{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Solrak97/clasificador_de_sentimientos/blob/main/Notebooks/Prueba_de_concepto_RAVDESS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mrjrCS157wwy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#! pip install kaggle wavio pydub keras-metrics tensorflow\n",
        "#! rm -rf *\n",
        "#! mkdir ~/.kaggle\n",
        "#! curl https://raw.githubusercontent.com/Solrak97/clasificador_de_sentimientos/main/kaggle.json > kaggle.json\n",
        "#! cp kaggle.json ~/.kaggle/\n",
        "#! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle datasets download uwrfkaggler/ravdess-emotional-speech-audio\n",
        "#! unzip ravdess-emotional-speech-audio.zip\n",
        "\n",
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from pydub import AudioSegment\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dropout, MaxPool1D, Flatten, Dense, ReLU, Input, BatchNormalization, Softmax\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ok5kblG7RD8"
      },
      "source": [
        "## Extraccion de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GevdxeWZ7dSw"
      },
      "outputs": [],
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\") \n",
        "\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "      \n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=84).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "           \n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "           \n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate, n_mels = 84).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "           \n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "           \n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "           \n",
        "    return result\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5RFJLUJ7V6t"
      },
      "source": [
        "## Enums de emociones dentro del dataset RAVDESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PWd_p1dD7lwX"
      },
      "outputs": [],
      "source": [
        "# we allow only these emotions ( feel free to tune this on your need )\n",
        "AVAILABLE_EMOTIONS = {\n",
        "    \"neutral\",\n",
        "    \"calm\",\n",
        "    \"happy\",\n",
        "    \"sad\",\n",
        "    \"angry\",\n",
        "    \"fearful\",\n",
        "    \"disgust\",\n",
        "    \"surprised\"\n",
        "}\n",
        "\n",
        "int_2_emotion = {\n",
        "    '01': \"neutral\",\n",
        "    '02': \"calm\",\n",
        "    '03': \"happy\",\n",
        "    '04': \"sad\",\n",
        "    '05': \"angry\",\n",
        "    '06': \"fearful\",\n",
        "    '07': \"disgust\",\n",
        "    '08': \"surprised\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función para carga de datos"
      ],
      "metadata": {
        "id": "nntDh6dnEu5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    X, y = [], []\n",
        "\n",
        "    for file in glob.glob(\"Actor_*/*.wav\"):\n",
        "      file_name=os.path.basename(file)\n",
        "      \n",
        "      # El audio viene en estereo para algunas partes\n",
        "      # Así que se pasa a mono\n",
        "      sound = AudioSegment.from_wav(file)\n",
        "      sound = sound.set_channels(1)\n",
        "      sound.export(file, format=\"wav\")\n",
        "  \n",
        "      name_split = file_name.split(\"-\")\n",
        "      emotion = int_2_emotion[name_split[2]]\n",
        "\n",
        "      # Limitación de emociones\n",
        "      if emotion not in AVAILABLE_EMOTIONS:\n",
        "        continue\n",
        "      \n",
        "      # Extracción de caracteristicas\n",
        "      features = extract_feature(file, mfcc=True, \n",
        "                                 chroma=True, mel=True, \n",
        "                                 contrast=True, tonnetz=True)\n",
        "      \n",
        "      \n",
        "      X.append(features)\n",
        "      y.append(emotion)\n",
        "\n",
        "    return (np.matrix(X), np.array(y))"
      ],
      "metadata": {
        "id": "s7LtmJo5FCh6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de datos"
      ],
      "metadata": {
        "id": "dIw9c9xWOM-M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "E5C_ASLa7p42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d38f6ae-610c-4421-b4ef-38016dea1fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1440,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "X, y = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replicación de la topología base"
      ],
      "metadata": {
        "id": "i4irKS14vWyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_baseline():\n",
        "  model = Sequential()\n",
        "\n",
        "  # input layer\n",
        "  model.add(Input(shape=(193, 1)))\n",
        "  \n",
        "  # Primer Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=255, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "\n",
        "  # Segund Convolutional layer\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  # Capa de Maxpooling\n",
        "  model.add(MaxPool1D(pool_size=8))\n",
        "\n",
        "  # 3 capas convolucionales intermedias\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(ReLU())\n",
        "\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(ReLU())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa convolucional final\n",
        "  model.add(Conv1D(strides=1, filters=128, kernel_size=5))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  # Capa densa, tiene la misma cantidad de neuronas que de clases a predecir\n",
        "  model.add(Dense(units=8))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Softmax())  \n",
        "  return model"
      ],
      "metadata": {
        "id": "uPswV9V2vdo0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pruebas del modelo base"
      ],
      "metadata": {
        "id": "leXRvpLTA4i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import metrics\n",
        "encoder = LabelEncoder()\n",
        "_y = encoder.fit_transform(y)\n",
        "base = build_baseline()\n",
        "#base.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "base.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=[\n",
        "        'MeanSquaredError',\n",
        "        'acc'\n",
        "    ])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, _y)\n",
        "\n",
        "# Model fit\n",
        "base.fit(X_train, y_train)\n",
        "\n",
        "# Model predict\n",
        "y_pred = base.predict(X_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "# Plot de matriz\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=encoder.classes_)\n",
        "\n",
        "\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKCeCFSzyIMk",
        "outputId": "e63abea2-0dc0-4ff8-f953-1a407757987d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 3s 13ms/step - loss: 2.0526 - mean_squared_error: 15.8965 - acc: 0.1861\n",
            "[[0.11019858 0.1568628  0.1276804  ... 0.12155099 0.11766429 0.12809113]\n",
            " [0.10859814 0.15587899 0.1284609  ... 0.12178741 0.12184825 0.1245279 ]\n",
            " [0.2503324  0.11212965 0.06125806 ... 0.08243667 0.14324087 0.06585706]\n",
            " ...\n",
            " [0.10864582 0.15511167 0.12994458 ... 0.12037726 0.1204299  0.12588984]\n",
            " [0.11146557 0.15669954 0.12769644 ... 0.12116181 0.11711467 0.12746684]\n",
            " [0.11227853 0.1524566  0.12946859 ... 0.12031659 0.11632673 0.12710305]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-73d6f37523d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Plot de matriz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Prueba de concepto RAVDESS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJMJSlgCuKVoHTHCemopXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}